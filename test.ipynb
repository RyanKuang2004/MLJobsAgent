{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectorstore_path = \"./chroma\"\n",
    "\n",
    "db = Chroma(\n",
    "    persist_directory=vectorstore_path,\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Responsibilities**\n",
      "\n",
      "*   Work closely with stakeholders to understand user requirements and translate them into scalable AI solutions.\n",
      "*   Continuously monitor and refine LLM systems to ensure optimal performance and alignment with evolving business needs.\n",
      "*   Experiment with and implement state-of-the-art methodologies to improve AI model performance and reliability.\n",
      "*   Collaborate with the broader team to prioritize and deliver impactful features on time.\n",
      "\n",
      "**Skillset & Experience**\n",
      "\n",
      "*   Proven experience deploying and optimizing large language models in production environments.\n",
      "*   Hands-on expertise in designing and implementing retrieval-augmented generation (RAG) systems.\n",
      "*   A strong background in building evaluation frameworks and improving AI systems iteratively.\n",
      "*   Familiarity with cloud platforms such as Google Cloud Platform (GCP) or similar environments.\n",
      "*   Adaptability and a problem-solving mindset to thrive in fast-paced, high-ambiguity situations.\n",
      "**We're interested in hearing from people who:**\n",
      "\n",
      "*   Can bring their expertise in Gen AI Models (LLMs, GANs, RL and RAG)\n",
      "*   Deliver innovative solutions using Gen AI technologies\n",
      "*   Show a thorough understanding of ML and deep learning principles and algorithms\n",
      "*   Are experienced with cloud platforms, ideally AWS\n",
      "*   Code in multiple languages including Python, and enjoy working with machine learning frameworks (such as TensorFlow, PyTorch, or Scikit-Learn)\n",
      "*   Work with large datasets, with knowledge of Data Pre-Processing Techniques\n",
      "\n",
      "**Tech skills**\n",
      "\n",
      "We use a broad range of tools, languages, and frameworks. We do not expect you to know them all but experience or exposure with some of these (or equivalents) will set you up for success in this team;\n",
      "\n",
      "*   Proficiency in languages such as Python, Java, or C++\n",
      "*   AWS services such as SageMaker, Bedrock, Rekognition, and Comprehend\n",
      "*   Docker or Kubernetes\n",
      "*   DevOps practices and tools such as Github Actions, Jenkins, Terraform\n",
      "*   Strong understanding and practical experience in statistics and machine learning, including causal inference and experimental design.\n",
      "*   Proficiency in Python, SQL, and machine learning frameworks (e.g TensorFlow, PyTorch)\n",
      "*   Strong background in AI/ML techniques, including NLP (traditional and LLMs), computer vision and predictive analytics.\n",
      "*   Strong knowledge of data science tools and technologies, including programming languages such as Python and the use of Git.\n",
      "*   Experience in platforms such as Snowflake, S3 and Databricks/SageMaker (beneficial).\n",
      "*   Familiar with cloud platforms such as AWS or Azure (beneficial).\n",
      "*   Experience with software development industry best practices.\n",
      "*   Strong stakeholder relationship management skills.\n",
      "*   Excellent problem-solving and analytical abilities.\n",
      "*   Awareness and understanding of Generative AI, Prompt Engineering and Large Language Models is highly desirable.  \n",
      "    \n",
      "*   Experience applying machine learning methods to products, features and/or services, including minimizing footprint, evaluating trade-offs, and pipeline work.  \n",
      "    \n",
      "*   Experience with cloud platforms, micro-services, and serverless architectures (ideally with AWS) and deployments, including devOps and CI/CD experience.  \n",
      "    \n",
      "*   An ability to communicate effectively with non-engineers of varying levels at the company including coaching both technical and non-technical skills.  \n",
      "    \n",
      "*   Previous experience with programming languages, techniques, and frameworks aligned with machine learning and software systems e.g. Python, Typescript, ML platforms such as Amazon SageMaker, LLMs platforms such as OpenAI, Amazon Bedrock, libraries like Pandas, & SKLearn.\n",
      "**Required Skills**  \n",
      "\n",
      "*   Strong understanding and practical experience in statistics and machine learning, including causal inference and experimental design.\n",
      "*   Proficiency in Python, SQL, and machine learning frameworks (e.g TensorFlow, PyTorch)\n",
      "*   Strong background in AI/ML techniques, including NLP (traditional and LLMs), computer vision and predictive analytics.\n",
      "*   Strong knowledge of data science tools and technologies, including programming languages such as Python and the use of Git.\n",
      "*   Experience in platforms such as Snowflake, S3 and Databricks/SageMaker (beneficial).\n",
      "*   Familiar with cloud platforms such as AWS or Azure\n"
     ]
    }
   ],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "documents = retriever.invoke(\"Does knowing how to build RAGs helpful for getting a job in Machine Learning\")\n",
    "for doc in documents:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://ai.nd.edu/news/deepseek-explained-what-is-it-and-is-it-safe-to-use/',\n",
       "  'content': 'DeepSeek refers to a new set of frontier AI models from a Chinese startup of the same name. DeepSeek has caused quite a stir in the AI world this week by demonstrating capabilities competitive with – or in some cases, better than – the latest models from OpenAI, while purportedly costing only a fraction of the money and compute power to create. DeepSeek models and their derivatives are all available for public download on Hugging Face, a prominent site for sharing AI/ML models. Did DeepSeek steal data to build its models? OpenAI recently accused DeepSeek of inappropriately using data pulled from one of its models to train DeepSeek. More About the DeepSeek Models'},\n",
       " {'url': 'https://www.techtarget.com/WhatIs/feature/DeepSeek-explained-Everything-you-need-to-know',\n",
       "  'content': \"DeepSeek, a Chinese AI firm, is disrupting the industry with its low-cost, open source large language models, challenging U.S. tech giants. DeepSeek focuses on developing open source LLMs. The company's first model was released in November 2023. Since the company was created in 2023, DeepSeek has released a series of generative AI models. Released in January 2025, this model is based on DeepSeek-V3 and is focused on advanced reasoning tasks directly competing with OpenAI's o1 model in performance, while maintaining a significantly lower cost structure. The low-cost development threatens the business model of U.S. tech companies that have invested billions in AI. In contrast with OpenAI, which is proprietary technology, DeepSeek is open source and free, challenging the revenue model of U.S. companies charging monthly fees for AI services.\"},\n",
       " {'url': 'https://www.bbc.co.uk/news/articles/c5yv5976z9po',\n",
       "  'content': \"An AI-powered chatbot by the Chinese company DeepSeek has quickly become the most downloaded free app on Apple's store, following its January release in the US. The app's sudden popularity, as well as DeepSeek's reportedly low costs compared to those of US-based AI companies, have thrown financial markets into a spin. DeepSeek's low cost creates concern for America's AI future DeepSeek was reportedly developed for a fraction of the cost of its rivals, raising questions about the future of America's AI dominance and the scale of investments US firms are planning. Prince William and Kate attend UK memorial after Holocaust survivors recall horrors of Auschwitz Chinese AI bot DeepSeek sparks US market turmoil, wiping $500bn off major tech firm Elsewhere on the BBC About the BBC\"},\n",
       " {'url': 'https://www.bbc.com/news/articles/c5yv5976z9po',\n",
       "  'content': 'An AI-powered chatbot by the Chinese company DeepSeek has quickly become the most downloaded free app on Apple\\'s store, following its January release in the US. The app\\'s sudden popularity, as well as DeepSeek\\'s reportedly low costs compared to those of US-based AI companies, have thrown financial markets into a spin. The company\\'s AI app is available for download in Apple\\'s App Store and online at its website. When the BBC asked the app what happened at Tiananmen Square on 4 June 1989, DeepSeek replied: \"I am sorry, I cannot answer that question. Watch: DeepSeek AI bot responds to BBC question about Tiananmen Square Nvidia shares sink as Chinese AI app spooks markets --------------------------------------------------- 2 hrs ago Technology About the BBC'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "web_search_tool = TavilySearchResults(max_results=4)\n",
    "web_search_tool.invoke({'query': \"What is deepseek\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
